{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "febd437d-911f-4220-b2d7-5be731b6fa2b",
   "metadata": {},
   "source": [
    "# Python scripts for training on the MNIST dataset using various machine learning and deep learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f61cfb-cbf7-4510-b4f1-5fc48f706cb7",
   "metadata": {},
   "source": [
    "## Prerequisites and Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b08b4785-412f-4a95-8b2c-802936c4fc16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading MNIST dataset...\n",
      "[INFO] MNIST dataset loaded successfully!\n",
      "[INFO] Splitting dataset...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "print(\"[INFO] Loading MNIST dataset...\")\n",
    "try:\n",
    "    mnist = fetch_openml('mnist_784', version=1)\n",
    "    X = mnist.data / 255.0\n",
    "    y = mnist.target.astype('int')\n",
    "    print(\"[INFO] MNIST dataset loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"[ERROR] Failed to load MNIST: {e}\")\n",
    "\n",
    "print(\"[INFO] Splitting dataset...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636b0a01-ea4b-4d93-8360-6602d45f9cc5",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1ec7d51-5d7f-49b0-bfb0-0bce101c87eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[MODEL] K-Nearest Neighbors Training...\n",
      "[INFO] KNN training complete.\n",
      "KNN Accuracy: 0.9712857142857143\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      1343\n",
      "           1       0.96      0.99      0.98      1600\n",
      "           2       0.97      0.97      0.97      1380\n",
      "           3       0.97      0.96      0.97      1433\n",
      "           4       0.97      0.96      0.97      1295\n",
      "           5       0.98      0.97      0.97      1273\n",
      "           6       0.98      0.99      0.99      1396\n",
      "           7       0.97      0.98      0.97      1503\n",
      "           8       0.99      0.94      0.96      1357\n",
      "           9       0.96      0.95      0.96      1420\n",
      "\n",
      "    accuracy                           0.97     14000\n",
      "   macro avg       0.97      0.97      0.97     14000\n",
      "weighted avg       0.97      0.97      0.97     14000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "print(\"\\n[MODEL] K-Nearest Neighbors Training...\")\n",
    "try:\n",
    "    knn = KNeighborsClassifier(n_neighbors=3)\n",
    "    knn.fit(X_train, y_train)\n",
    "    print(\"[INFO] KNN training complete.\")\n",
    "    y_pred_knn = knn.predict(X_test)\n",
    "    print(\"KNN Accuracy:\", accuracy_score(y_test, y_pred_knn))\n",
    "    print(classification_report(y_test, y_pred_knn))\n",
    "except Exception as e:\n",
    "    print(f\"[ERROR] KNN failed: {e}\")\n",
    "finally:\n",
    "    del knn\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ee7fa7-2d8e-4a1c-86e5-121dcec7ce58",
   "metadata": {},
   "source": [
    "## Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15f31a68-35b4-4ac0-b70b-1b3b41bbc389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[MODEL] Support Vector Machine Training...\n",
      "[INFO] SVM training complete.\n",
      "SVM Accuracy (on partial data): 0.954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97        95\n",
      "           1       0.96      0.99      0.98       104\n",
      "           2       0.91      0.95      0.93        95\n",
      "           3       0.95      0.92      0.93       119\n",
      "           4       0.92      0.98      0.95        88\n",
      "           5       0.94      0.94      0.94        90\n",
      "           6       0.96      0.99      0.97        97\n",
      "           7       0.95      0.95      0.95       103\n",
      "           8       1.00      0.90      0.95       101\n",
      "           9       0.98      0.94      0.96       108\n",
      "\n",
      "    accuracy                           0.95      1000\n",
      "   macro avg       0.95      0.96      0.95      1000\n",
      "weighted avg       0.95      0.95      0.95      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "print(\"\\n[MODEL] Support Vector Machine Training...\")\n",
    "try:\n",
    "    svm = SVC(kernel='rbf')\n",
    "    svm.fit(X_train[:5000], y_train[:5000])  # reduced for speed\n",
    "    print(\"[INFO] SVM training complete.\")\n",
    "    y_pred_svm = svm.predict(X_test[:1000])\n",
    "    print(\"SVM Accuracy (on partial data):\", accuracy_score(y_test[:1000], y_pred_svm))\n",
    "    print(classification_report(y_test[:1000], y_pred_svm))\n",
    "except Exception as e:\n",
    "    print(f\"[ERROR] SVM failed: {e}\")\n",
    "finally:\n",
    "    del svm\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ab1106-b4ee-45c7-a211-f88ddf977010",
   "metadata": {},
   "source": [
    "  ## Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30d139bb-69b3-4748-84d2-5e3cccc7d71e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[MODEL] Logistic Regression Training...\n",
      "[INFO] Logistic Regression training complete.\n",
      "Logistic Regression Accuracy: 0.9202857142857143\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1343\n",
      "           1       0.95      0.97      0.96      1600\n",
      "           2       0.91      0.89      0.90      1380\n",
      "           3       0.90      0.90      0.90      1433\n",
      "           4       0.92      0.93      0.92      1295\n",
      "           5       0.87      0.89      0.88      1273\n",
      "           6       0.95      0.95      0.95      1396\n",
      "           7       0.93      0.94      0.94      1503\n",
      "           8       0.90      0.87      0.88      1357\n",
      "           9       0.90      0.89      0.90      1420\n",
      "\n",
      "    accuracy                           0.92     14000\n",
      "   macro avg       0.92      0.92      0.92     14000\n",
      "weighted avg       0.92      0.92      0.92     14000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "print(\"\\n[MODEL] Logistic Regression Training...\")\n",
    "try:\n",
    "    lr = LogisticRegression(max_iter=100)\n",
    "    lr.fit(X_train, y_train)\n",
    "    print(\"[INFO] Logistic Regression training complete.\")\n",
    "    y_pred_lr = lr.predict(X_test)\n",
    "    print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred_lr))\n",
    "    print(classification_report(y_test, y_pred_lr))\n",
    "except Exception as e:\n",
    "    print(f\"[ERROR] Logistic Regression failed: {e}\")\n",
    "finally:\n",
    "    del lr\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f2c684-8472-4846-8dd6-b4a0e44d8df4",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f976d9e4-f826-4509-a6a2-bba5e7a0c22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[MODEL] Decision Tree Training...\n",
      "[INFO] Decision Tree training complete.\n",
      "Decision Tree Accuracy: 0.8715\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92      1343\n",
      "           1       0.94      0.95      0.95      1600\n",
      "           2       0.86      0.83      0.85      1380\n",
      "           3       0.83      0.84      0.83      1433\n",
      "           4       0.85      0.87      0.86      1295\n",
      "           5       0.84      0.82      0.83      1273\n",
      "           6       0.90      0.90      0.90      1396\n",
      "           7       0.92      0.90      0.91      1503\n",
      "           8       0.81      0.81      0.81      1357\n",
      "           9       0.84      0.85      0.84      1420\n",
      "\n",
      "    accuracy                           0.87     14000\n",
      "   macro avg       0.87      0.87      0.87     14000\n",
      "weighted avg       0.87      0.87      0.87     14000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "print(\"\\n[MODEL] Decision Tree Training...\")\n",
    "try:\n",
    "    dt = DecisionTreeClassifier()\n",
    "    dt.fit(X_train, y_train)\n",
    "    print(\"[INFO] Decision Tree training complete.\")\n",
    "    y_pred_dt = dt.predict(X_test)\n",
    "    print(\"Decision Tree Accuracy:\", accuracy_score(y_test, y_pred_dt))\n",
    "    print(classification_report(y_test, y_pred_dt))\n",
    "except Exception as e:\n",
    "    print(f\"[ERROR] Decision Tree failed: {e}\")\n",
    "finally:\n",
    "    del dt\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949b3ebe-93f8-4362-96f2-d4233dcfa1f6",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2cf424b-8a3f-4a9a-8d70-3616b20b3985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[MODEL] Random Forest Training...\n",
      "[INFO] Random Forest training complete.\n",
      "Random Forest Accuracy: 0.9673571428571428\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1343\n",
      "           1       0.98      0.98      0.98      1600\n",
      "           2       0.95      0.97      0.96      1380\n",
      "           3       0.96      0.95      0.96      1433\n",
      "           4       0.96      0.97      0.97      1295\n",
      "           5       0.97      0.96      0.97      1273\n",
      "           6       0.98      0.98      0.98      1396\n",
      "           7       0.97      0.97      0.97      1503\n",
      "           8       0.96      0.95      0.96      1357\n",
      "           9       0.95      0.95      0.95      1420\n",
      "\n",
      "    accuracy                           0.97     14000\n",
      "   macro avg       0.97      0.97      0.97     14000\n",
      "weighted avg       0.97      0.97      0.97     14000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "print(\"\\n[MODEL] Random Forest Training...\")\n",
    "try:\n",
    "    rf = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "    rf.fit(X_train, y_train)\n",
    "    print(\"[INFO] Random Forest training complete.\")\n",
    "    y_pred_rf = rf.predict(X_test)\n",
    "    print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "    print(classification_report(y_test, y_pred_rf))\n",
    "except Exception as e:\n",
    "    print(f\"[ERROR] Random Forest failed: {e}\")\n",
    "finally:\n",
    "    del rf\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3bafbc-ead8-434d-be87-1687794d3cf9",
   "metadata": {},
   "source": [
    "## Multi-Layer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6d4c301-e87e-4c47-b3a7-141f78242715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[MODEL] Multi-Layer Perceptron Training...\n",
      "[INFO] MLP training complete.\n",
      "MLP Accuracy: 0.9734285714285714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      1343\n",
      "           1       0.99      0.98      0.99      1600\n",
      "           2       0.95      0.98      0.97      1380\n",
      "           3       0.96      0.97      0.97      1433\n",
      "           4       0.98      0.96      0.97      1295\n",
      "           5       0.98      0.97      0.98      1273\n",
      "           6       0.98      0.99      0.98      1396\n",
      "           7       0.98      0.97      0.97      1503\n",
      "           8       0.97      0.95      0.96      1357\n",
      "           9       0.96      0.97      0.96      1420\n",
      "\n",
      "    accuracy                           0.97     14000\n",
      "   macro avg       0.97      0.97      0.97     14000\n",
      "weighted avg       0.97      0.97      0.97     14000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "print(\"\\n[MODEL] Multi-Layer Perceptron Training...\")\n",
    "try:\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=20)\n",
    "    mlp.fit(X_train, y_train)\n",
    "    print(\"[INFO] MLP training complete.\")\n",
    "    y_pred_mlp = mlp.predict(X_test)\n",
    "    print(\"MLP Accuracy:\", accuracy_score(y_test, y_pred_mlp))\n",
    "    print(classification_report(y_test, y_pred_mlp))\n",
    "except Exception as e:\n",
    "    print(f\"[ERROR] MLP failed: {e}\")\n",
    "finally:\n",
    "    del mlp\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea263203-b13a-4a42-8b17-83ae8f689960",
   "metadata": {},
   "source": [
    "## Artificial Neural Network (ANN) with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2df57d9a-d128-4614-8dde-1ae8466225e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[MODEL] Artificial Neural Network Training...\n",
      "Epoch 1/5\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8285 - loss: 0.6132\n",
      "Epoch 2/5\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9573 - loss: 0.1474\n",
      "Epoch 3/5\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9712 - loss: 0.0951\n",
      "Epoch 4/5\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9778 - loss: 0.0743\n",
      "Epoch 5/5\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9825 - loss: 0.0561\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9728 - loss: 0.0915\n",
      "ANN Accuracy: 0.9717857241630554\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "print(\"\\n[MODEL] Artificial Neural Network Training...\")\n",
    "try:\n",
    "    y_train_cat = to_categorical(y_train, 10)\n",
    "    y_test_cat = to_categorical(y_test, 10)\n",
    "\n",
    "    ann = Sequential([\n",
    "        Dense(128, activation='relu', input_shape=(784,)),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "    ann.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    ann.fit(X_train, y_train_cat, epochs=5, batch_size=128, verbose=1)\n",
    "    loss, acc = ann.evaluate(X_test, y_test_cat)\n",
    "    print(\"ANN Accuracy:\", acc)\n",
    "except Exception as e:\n",
    "    print(f\"[ERROR] ANN failed: {e}\")\n",
    "finally:\n",
    "    del ann\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa602ca-8f3b-4a80-adea-42aa6f2920bf",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd8607ea-bb8f-4df9-a5cc-ab479ec31702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[MODEL] Convolutional Neural Network Training...\n",
      "Epoch 1/5\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 24ms/step - accuracy: 0.8197 - loss: 0.5893\n",
      "Epoch 2/5\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 0.9710 - loss: 0.0974\n",
      "Epoch 3/5\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9793 - loss: 0.0652\n",
      "Epoch 4/5\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9839 - loss: 0.0511\n",
      "Epoch 5/5\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 0.9859 - loss: 0.0438\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9878 - loss: 0.0335\n",
      "CNN Accuracy: 0.9884285926818848\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dropout, Reshape\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "print(\"\\n[MODEL] Convolutional Neural Network Training...\")\n",
    "try:\n",
    "    X_train_cnn = X_train.values.reshape(-1, 28, 28, 1)\n",
    "    X_test_cnn = X_test.values.reshape(-1, 28, 28, 1)\n",
    "\n",
    "    cnn = Sequential([\n",
    "        Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(28,28,1)),\n",
    "        MaxPooling2D(pool_size=(2,2)),\n",
    "        Conv2D(64, (3,3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2,2)),\n",
    "        Flatten(),\n",
    "        Dropout(0.5),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "    cnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    cnn.fit(X_train_cnn, y_train_cat, epochs=5, batch_size=128, verbose=1)\n",
    "    loss, acc = cnn.evaluate(X_test_cnn, y_test_cat)\n",
    "    print(\"CNN Accuracy:\", acc)\n",
    "except Exception as e:\n",
    "    print(f\"[ERROR] CNN failed: {e}\")\n",
    "finally:\n",
    "    del cnn\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c8578b-f6ad-4f48-b73a-fc02a980eb2a",
   "metadata": {},
   "source": [
    "## Recurrent Neural Network (RNN) using LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22fc0821-e3aa-48eb-bf6c-c6690201c3af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[MODEL] Recurrent Neural Network Training...\n",
      "Epoch 1/5\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 53ms/step - accuracy: 0.6573 - loss: 1.0215\n",
      "Epoch 2/5\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 52ms/step - accuracy: 0.9471 - loss: 0.1721\n",
      "Epoch 3/5\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 52ms/step - accuracy: 0.9657 - loss: 0.1129\n",
      "Epoch 4/5\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 53ms/step - accuracy: 0.9742 - loss: 0.0840\n",
      "Epoch 5/5\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 52ms/step - accuracy: 0.9808 - loss: 0.0614\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9692 - loss: 0.0997\n",
      "RNN Accuracy: 0.9698571562767029\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "print(\"\\n[MODEL] Recurrent Neural Network Training...\")\n",
    "try:\n",
    "    X_train_rnn = X_train.values.reshape(-1, 28, 28)\n",
    "    X_test_rnn = X_test.values.reshape(-1, 28, 28)\n",
    "\n",
    "    rnn = Sequential([\n",
    "        LSTM(128, input_shape=(28,28)),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "    rnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    rnn.fit(X_train_rnn, y_train_cat, epochs=5, batch_size=128, verbose=1)\n",
    "    loss, acc = rnn.evaluate(X_test_rnn, y_test_cat)\n",
    "    print(\"RNN Accuracy:\", acc)\n",
    "except Exception as e:\n",
    "    print(f\"[ERROR] RNN failed: {e}\")\n",
    "finally:\n",
    "    del rnn\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592100ce-899b-4f8b-a966-69eed6e6024c",
   "metadata": {},
   "source": [
    "## Voting Classifier (Ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "053b1a81-d055-46ca-9d4d-f27ae8d25d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[MODEL] Voting Classifier Ensemble...\n",
      "Voting Classifier Accuracy: 0.9672857142857143\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      1343\n",
      "           1       0.97      0.99      0.98      1600\n",
      "           2       0.95      0.97      0.96      1380\n",
      "           3       0.95      0.96      0.95      1433\n",
      "           4       0.97      0.97      0.97      1295\n",
      "           5       0.97      0.96      0.96      1273\n",
      "           6       0.98      0.98      0.98      1396\n",
      "           7       0.97      0.97      0.97      1503\n",
      "           8       0.97      0.94      0.95      1357\n",
      "           9       0.97      0.95      0.96      1420\n",
      "\n",
      "    accuracy                           0.97     14000\n",
      "   macro avg       0.97      0.97      0.97     14000\n",
      "weighted avg       0.97      0.97      0.97     14000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "print(\"\\n[MODEL] Voting Classifier Ensemble...\")\n",
    "try:\n",
    "    # Simple fast models due to memory constraints\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "    clf1 = LogisticRegression(max_iter=100)\n",
    "    clf2 = RandomForestClassifier(n_estimators=50)\n",
    "    clf3 = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "    ensemble = VotingClassifier(estimators=[\n",
    "        ('lr', clf1), ('rf', clf2), ('knn', clf3)\n",
    "    ], voting='hard')\n",
    "\n",
    "    ensemble.fit(X_train, y_train)\n",
    "    y_pred_ensemble = ensemble.predict(X_test)\n",
    "    print(\"Voting Classifier Accuracy:\", accuracy_score(y_test, y_pred_ensemble))\n",
    "    print(classification_report(y_test, y_pred_ensemble))\n",
    "except Exception as e:\n",
    "    print(f\"[ERROR] Voting Classifier failed: {e}\")\n",
    "finally:\n",
    "    del ensemble\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091a12b4-74b8-4123-ba6c-7df2d39605a4",
   "metadata": {},
   "source": [
    "This implemention and comparion a wide range of machine learning and deep learning models for the MNIST digit classification task tells us about the performance of different ML models in image based learning. Classical models like KNN and Random Forest showed impressive performance, with KNN achieving 97.13% accuracy and Random Forest closely following with 96.40%. Among deep learning models, the CNN clearly stood out, reaching the highest accuracy of 98.64%, which aligns with the known strength of convolutional architectures in image-related tasks.\n",
    "\n",
    "We also implemented a Voting Classifier to combine the strengths of multiple traditional models, achieving a robust 96.03% accuracy. Although not surpassing CNN, this ensemble method proved effective in increasing stability and generalization.\n",
    "\n",
    "Overall, this comprehensive approach provided insights into the strengths and trade-offs of various models. The CNN emerged as the top performer, but ensemble learning demonstrated its value, especially in scenarios where deep learning might be resource-intensive."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
